{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGLa6K6HDlH/QcuRFpK88i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu-0/learn-pytorch/blob/main/05_modular_pytorch_with_argparse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMziuTXdxgr5",
        "outputId": "8dbf05da-6980-4a77-b95d-d89fde215594"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a directory `going_modular` and store all `.py` scripts there"
      ],
      "metadata": {
        "id": "ww7svnhscJYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('going_modular', exist_ok=True)"
      ],
      "metadata": {
        "id": "Ea530w5hcWID"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Writing `get_data.py` for Data Downloading"
      ],
      "metadata": {
        "id": "9a9ZKY5Oa_g8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9nKNYVcKYo6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a58bc8-d7c1-4712-a315-a792117d283c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/get_data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile going_modular/get_data.py\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# setup path\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# download if, image folder doesn't exists\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exists...skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exists...creating one\")\n",
        "  image_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "\n",
        "# download zip file from daniel github\n",
        "with open(data_path/ \"pizza_steak_sushi.zip\", 'wb') as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print('Downloading....the github zip file')\n",
        "  f.write(request.content)\n",
        "\n",
        "# unzip the data\n",
        "with zipfile.ZipFile(data_path/'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "  print('Unzipping the zip file')\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "# remove the zip file\n",
        "os.remove(data_path/'pizza_steak_sushi.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Writing `data_setup.py` file to create Dataset and DataLoaders"
      ],
      "metadata": {
        "id": "BQHPFwr1dadn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(train_dir: str,\n",
        "                       test_dir: str,\n",
        "                       transform: transforms.Compose,\n",
        "                       batch_size: int,\n",
        "                       num_workers: NUM_WORKERS):\n",
        "\n",
        "  # load image data using ImageFolder\n",
        "  train_data = datasets.ImageFolder(train_dir,\n",
        "                                  transform= transform,)\n",
        "\n",
        "  test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform= transform)\n",
        "\n",
        "  # get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  #turn image dataset into dataloaders\n",
        "  train_dataloader = DataLoader(train_data,\n",
        "                               batch_size = batch_size,\n",
        "                               num_workers= NUM_WORKERS,\n",
        "                               shuffle = True)\n",
        "  test_dataloader = DataLoader(test_data,\n",
        "                              batch_size = batch_size,\n",
        "                              shuffle = False,\n",
        "                               num_workers= NUM_WORKERS)\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-aCrskcbreF",
        "outputId": "cb1be6da-3af2-445c-a283-b7ae277736ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Writing `model_builder.py` to create Model"
      ],
      "metadata": {
        "id": "nHaWV7ung8zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int)-> None:\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2) # by default equal to kernel_size\n",
        "    )\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2) # by default equal to kernel_size\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x)\n",
        "    x = self.conv_block2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "    # return self.classifier(self.conv_block2(self.conv_block1(x))) # <--using operation fusion we can do all above in single step\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En_pgG2ug4LT",
        "outputId": "6c657aaa-f89d-454c-96e6-642fc2757cc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Writing `engine.py`\n",
        "to put `train_step()` , `test_step()` and `train()` functions together"
      ],
      "metadata": {
        "id": "xV77dIOdi2hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\n",
        "import torchmetrics\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "\n",
        "# train step func\n",
        "def train_step(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    accuracy_fn: torchmetrics.Accuracy,\n",
        "    device: torch.device)-> Tuple[float, float]:\n",
        "\n",
        "  # to train mode\n",
        "  model.train()\n",
        "\n",
        "  train_loss, train_acc = 0,0\n",
        "\n",
        "  # loop through each batch\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    #.to(device)\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # do the forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # loss backward (backprop)\n",
        "    loss.backward()\n",
        "\n",
        "    # optimizer step (grad descent)\n",
        "    optimizer.step()\n",
        "\n",
        "    # accuracy\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "\n",
        "\n",
        "  # avg per batch\n",
        "  train_loss /=len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "\n",
        "# test step func\n",
        "def test_step(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    accuracy_fn: torchmetrics.Accuracy,\n",
        "    device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "  # to eval mode\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, test_acc = 0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "      # to.device\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      # do forward pass -> raw logits\n",
        "      test_pred_logits = model(X)\n",
        "\n",
        "      # calculate the loss\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # accuracy\n",
        "      test_acc += accuracy_fn(test_pred_logits, y)\n",
        "\n",
        "  # avg\n",
        "  test_loss = test_loss/ len(dataloader)\n",
        "  test_acc = test_acc/ len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "\n",
        "#train func\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          accuracy_fn: torchmetrics.Accuracy,\n",
        "          epochs: int,\n",
        "          device= torch.device)-> dict[str, List]:\n",
        "\n",
        "  # empty result dict\n",
        "  results = {'train_loss': [],\n",
        "             'train_acc': [],\n",
        "             'test_loss': [],\n",
        "             'test_acc': []}\n",
        "  # loop\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader = train_dataloader,\n",
        "                                       loss_fn = loss_fn,\n",
        "                                       optimizer= optimizer,\n",
        "                                       accuracy_fn=accuracy_fn,\n",
        "                                       device = device)\n",
        "\n",
        "    test_loss, test_acc = test_step(model = model,\n",
        "                                    dataloader = test_dataloader,\n",
        "                                    loss_fn = loss_fn,\n",
        "                                    accuracy_fn=accuracy_fn,\n",
        "                                    device = device)\n",
        "    # print out what's happening\n",
        "    print(f'Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test acc: {test_acc:.4f}')\n",
        "\n",
        "    # update the dict\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['test_acc'].append(test_acc)\n",
        "\n",
        "  #return the end results\n",
        "  return results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evzc1T3siwiB",
        "outputId": "9ee711fb-debe-4656-eccb-6e2dfcb63ec6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing `utils.py` to save the model"
      ],
      "metadata": {
        "id": "XLhMDMuAm9bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# func to save the model after training\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "\n",
        "  # create target dir\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok= True)\n",
        "\n",
        "  # create model save path\n",
        "  assert model_name.endswith('.pth') or model_name.endswith('pt')\n",
        "  model_save_path = target_dir_path /model_name\n",
        "\n",
        "  # save model state_dict()\n",
        "  print(f'Saving model to: {model_save_path}')\n",
        "  torch.save(obj= model.state_dict(),\n",
        "             f = model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYmf7A0tm6UV",
        "outputId": "69f990cd-4f4e-4eb9-9da0-de71d8665be4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Writing `train.py` to train, evaluate and save the model\n",
        "\n",
        "- combining all the functionality of all the other python scripts\n",
        "- so that we can train a model using a single line of code\n",
        "```\n",
        "python train.py\n",
        "```\n",
        "1. import all the dependencies\n",
        "2. import other modules in `going_modular` directory\n",
        "3. setup hyperparams\n",
        "4. train and test fun\n",
        "5. device-agnostic code\n",
        "6. data transforms\n",
        "7. dataloaders\n",
        "8. create model\n",
        "9. setup loss and optimizer\n",
        "10. train the model\n",
        "11. save the model\n"
      ],
      "metadata": {
        "id": "MPx6UbkLoxlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py\n",
        "import os\n",
        "import torch\n",
        "import torchmetrics\n",
        "import get_data, data_setup, engine, model_builder, utils\n",
        "from torchvision import transforms\n",
        "\n",
        "# hyperparams\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "\n",
        "# directories\n",
        "train_dir = get_data.image_path/'train'\n",
        "test_dir = get_data.image_path/'test'\n",
        "\n",
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# transforms\n",
        "data_transform = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "# dataloaders from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir = train_dir,\n",
        "    test_dir = test_dir,\n",
        "    transform = data_transform,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers = NUM_WORKERS\n",
        ")\n",
        "\n",
        "# model from mode_builder.py\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units= HIDDEN_UNITS,\n",
        "    output_shape = len(class_names)\n",
        ").to(device)\n",
        "\n",
        "# loss, optimizer and accuracy\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "accuracy_fn = torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr= LEARNING_RATE)\n",
        "\n",
        "# training using engine.py\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn= accuracy_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs = NUM_EPOCHS,\n",
        "             device = device)\n",
        "\n",
        "# save model using utils.py\n",
        "utils.save_model(model=model,\n",
        "                 target_dir='models',\n",
        "                 model_name='test_modular_tinyvgg.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GImt8mX-olPJ",
        "outputId": "e0357a44-e398-4e12-f2dd-58676ec6059a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's train out model"
      ],
      "metadata": {
        "id": "3fhGIHERwdSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIj5KmqCwZpe",
        "outputId": "e0a2d8c9-f8ec-470d-9665-f60f7cb7bdde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists...skipping download\n",
            "Downloading....the github zip file\n",
            "Unzipping the zip file\n",
            "  0% 0/5 [00:00<?, ?it/s]Epoch: 0 | Train Loss: 1.0904 | Train acc: 0.4141 | Test Loss: 1.1361 | Test acc: 0.2604\n",
            " 20% 1/5 [00:01<00:05,  1.32s/it]Epoch: 1 | Train Loss: 1.1413 | Train acc: 0.3047 | Test Loss: 1.1254 | Test acc: 0.2604\n",
            " 40% 2/5 [00:02<00:03,  1.07s/it]Epoch: 2 | Train Loss: 1.0876 | Train acc: 0.4336 | Test Loss: 1.1187 | Test acc: 0.3125\n",
            " 60% 3/5 [00:03<00:02,  1.01s/it]Epoch: 3 | Train Loss: 1.0911 | Train acc: 0.4570 | Test Loss: 1.1074 | Test acc: 0.3125\n",
            " 80% 4/5 [00:04<00:00,  1.03it/s]Epoch: 4 | Train Loss: 1.0591 | Train acc: 0.5469 | Test Loss: 1.0453 | Test acc: 0.5634\n",
            "100% 5/5 [00:05<00:00,  1.02s/it]\n",
            "Saving model to: models/test_modular_tinyvgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizing Python `argparse` Module to able to send the `train.py` custo hyperparams\n",
        "\n",
        "- add argument flag to\n",
        " * train/test dir\n",
        " * learning rate\n",
        " * num of epochs\n",
        " * batch size\n",
        " * num of hidden units\n",
        "- keep the default values of each also"
      ],
      "metadata": {
        "id": "KyB7MyOvg_Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train_with_argparse.py\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torchmetrics\n",
        "import get_data, data_setup, engine, model_builder, utils\n",
        "from torchvision import transforms\n",
        "\n",
        "# create a parser\n",
        "parser = argparse.ArgumentParser(description= 'Get some hyperparameters')\n",
        "\n",
        "# get an arg for num of epochs\n",
        "parser.add_argument('--num_epochs',\n",
        "                    default = 10,\n",
        "                    type=int,\n",
        "                    help='The number of epochs to train for')\n",
        "\n",
        "# get an arg for batch size\n",
        "parser.add_argument('--batch_size',\n",
        "                    default=32,\n",
        "                    type=int,\n",
        "                    help='The number of samples to train per batch')\n",
        "\n",
        "# get an arg for hidden units\n",
        "parser.add_argument('--hidden_units',\n",
        "                    default=10,\n",
        "                    type=int,\n",
        "                    help='The number of hidden units in hidden layers')\n",
        "\n",
        "# get an arg for learning rate\n",
        "parser.add_argument('--learning_rate',\n",
        "                    default=0.003,\n",
        "                    type=float,\n",
        "                    help='Learning rate to train the model')\n",
        "\n",
        "# get an arg for train directory\n",
        "parser.add_argument('--train_dir',\n",
        "                    default=get_data.image_path/'train',\n",
        "                    type=str,\n",
        "                    help='Path of file directory to train the model')\n",
        "\n",
        "# get an arg for test directory\n",
        "parser.add_argument('--test_dir',\n",
        "                    default=get_data.image_path/'test',\n",
        "                    type=str,\n",
        "                    help='Path of file directory to test the model')\n",
        "\n",
        "# get an argument from the parser\n",
        "args = parser.parse_args()\n",
        "\n",
        "# hyperparams\n",
        "NUM_EPOCHS = args.num_epochs\n",
        "BATCH_SIZE = args.batch_size\n",
        "HIDDEN_UNITS = args.hidden_units\n",
        "LEARNING_RATE = args.learning_rate\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "\n",
        "\n",
        "# directories\n",
        "train_dir = args.train_dir\n",
        "test_dir = args.test_dir\n",
        "\n",
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# transforms\n",
        "data_transform = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "# dataloaders from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir = train_dir,\n",
        "    test_dir = test_dir,\n",
        "    transform = data_transform,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    num_workers = NUM_WORKERS\n",
        ")\n",
        "\n",
        "# model from mode_builder.py\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units= HIDDEN_UNITS,\n",
        "    output_shape = len(class_names)\n",
        ").to(device)\n",
        "\n",
        "# loss, optimizer and accuracy\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "accuracy_fn = torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr= LEARNING_RATE)\n",
        "\n",
        "# training using engine.py\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn= accuracy_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs = NUM_EPOCHS,\n",
        "             device = device)\n",
        "\n",
        "# save model using utils.py\n",
        "utils.save_model(model=model,\n",
        "                 target_dir='models',\n",
        "                 model_name='test_modular_tinyvgg.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txYOvwvsg-WG",
        "outputId": "bd057a34-ebc6-4498-a510-2c924aa4b194"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/train_with_argparse.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training with hyperpraramas\n",
        "\n",
        "!python going_modular/train_with_argparse.py --num_epochs 8 --batch_size 64 --hidden_units 96 --learning_rate 0.0003"
      ],
      "metadata": {
        "id": "UsJYvk_5wkcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5ab0ab-bc44-4909-f519-790c7a5d72a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exists...skipping download\n",
            "Downloading....the github zip file\n",
            "Unzipping the zip file\n",
            "  0% 0/8 [00:00<?, ?it/s]Epoch: 0 | Train Loss: 1.1014 | Train acc: 0.3243 | Test Loss: 1.1026 | Test acc: 0.1953\n",
            " 12% 1/8 [00:03<00:24,  3.49s/it]Epoch: 1 | Train Loss: 1.0914 | Train acc: 0.3487 | Test Loss: 1.1336 | Test acc: 0.1953\n",
            " 25% 2/8 [00:05<00:15,  2.56s/it]Epoch: 2 | Train Loss: 1.0728 | Train acc: 0.3717 | Test Loss: 1.0651 | Test acc: 0.2876\n",
            " 38% 3/8 [00:07<00:10,  2.19s/it]Epoch: 3 | Train Loss: 1.0349 | Train acc: 0.5311 | Test Loss: 0.9936 | Test acc: 0.4474\n",
            " 50% 4/8 [00:08<00:06,  1.73s/it]Epoch: 4 | Train Loss: 0.9850 | Train acc: 0.5580 | Test Loss: 1.1396 | Test acc: 0.2564\n",
            " 62% 5/8 [00:09<00:04,  1.47s/it]Epoch: 5 | Train Loss: 0.8817 | Train acc: 0.5924 | Test Loss: 1.1586 | Test acc: 0.2876\n",
            " 75% 6/8 [00:10<00:02,  1.32s/it]Epoch: 6 | Train Loss: 0.8833 | Train acc: 0.5778 | Test Loss: 0.9660 | Test acc: 0.5682\n",
            " 88% 7/8 [00:11<00:01,  1.22s/it]Epoch: 7 | Train Loss: 0.8255 | Train acc: 0.6510 | Test Loss: 1.0969 | Test acc: 0.3253\n",
            "100% 8/8 [00:12<00:00,  1.53s/it]\n",
            "Saving model to: models/test_modular_tinyvgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing `predict.py`\n",
        "to make prediction on custom image given a file path"
      ],
      "metadata": {
        "id": "4CDaRf7yn0dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/predict.py\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import argparse\n",
        "import model_builder\n",
        "\n",
        "# creating a parser\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# get image path\n",
        "parser.add_argument('--image',\n",
        "                    help= 'Path directory of image to predict on')\n",
        "\n",
        "# get model path\n",
        "parser.add_argument('--model_path',\n",
        "                    type=str,\n",
        "                    default= 'models/test_modular_tinyvgg.pth',\n",
        "                    help= 'Target Model filepath to use for prediction')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "# setup class names\n",
        "class_names = ['pizza', 'steak', 'sushi']\n",
        "\n",
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# get the image path\n",
        "IMG_PATH= args.image\n",
        "print(f'[INFO] Predicting on {IMG_PATH}')\n",
        "\n",
        "# function to load the model\n",
        "def load_model(filepath = args.model_path):\n",
        "\n",
        "  # same hyperparamas as saved model\n",
        "  model= model_builder.TinyVGG(input_shape=3,\n",
        "                               hidden_units = 96,\n",
        "                               output_shape=3).to(device)\n",
        "\n",
        "  print(f'[INFO] loading the saved model from: {filepath}')\n",
        "\n",
        "  # load the saved model state_dict\n",
        "  model.load_state_dict(torch.load(filepath))\n",
        "\n",
        "  return model\n",
        "\n",
        "# function to load in model and make prediction on the image\n",
        "def predict_image(image_path= IMG_PATH,\n",
        "                  filepath = args.model_path):\n",
        "\n",
        "  # load the model\n",
        "  model = load_model(filepath)\n",
        "\n",
        "  # load the image and preprocess it\n",
        "  image = torchvision.io.read_image(str(image_path)).type(torch.float32)/255\n",
        "\n",
        "  # make transform -> resize the image\n",
        "  transform = torchvision.transforms.Resize(size = (64,64))\n",
        "  image = transform(image)\n",
        "\n",
        "  # predict on image\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    image = image.to(device)\n",
        "\n",
        "    # add batch_size dim and make pred\n",
        "    pred_logits = model(image.unsqueeze(dim=0))\n",
        "\n",
        "    # pred probs\n",
        "    pred_probs = torch.softmax(pred_logits, dim=1)\n",
        "\n",
        "    #pred labels\n",
        "    pred_label = torch.argmax(pred_probs, dim=1)\n",
        "    pred_label_class = class_names[pred_label]\n",
        "\n",
        "  print(f'[INFO] Pred class: {pred_label_class}, Pred prob: {pred_probs.max():.3f}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  predict_image()"
      ],
      "metadata": {
        "id": "oD8h9_RFlnGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562cf38d-4009-44cc-e9f4-2626c22a65e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/predict.py --image /content/data/pizza_steak_sushi/test/sushi/1245193.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1mKfijiAhVu",
        "outputId": "6c941cd2-8fcf-45a3-929a-dc517dbd41d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Predicting on /content/data/pizza_steak_sushi/test/sushi/1245193.jpg\n",
            "[INFO] loading the saved model from: models/test_modular_tinyvgg.pth\n",
            "/content/going_modular/predict.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(filepath))\n",
            "[INFO] Pred class: sushi, Pred prob: 0.588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eS3A2In5Bojt"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}